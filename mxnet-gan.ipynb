{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.datasets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a47efebbd31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.datasets"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-14 17:22:50.271749. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import logging\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "def make_dcgan_sym(ngf, ndf, nc, no_bias=True, fix_gamma=True, eps=1e-5 + 1e-12):\n",
    "    BatchNorm = mx.sym.BatchNorm\n",
    "    rand = mx.sym.Variable('rand')\n",
    "\n",
    "    g1 = mx.sym.Deconvolution(rand, name='g1', kernel=(4,4), num_filter=ngf*8, no_bias=no_bias)\n",
    "    gbn1 = BatchNorm(g1, name='gbn1', fix_gamma=fix_gamma, eps=eps)\n",
    "    gact1 = mx.sym.Activation(gbn1, name='gact1', act_type='relu')\n",
    "\n",
    "    g2 = mx.sym.Deconvolution(gact1, name='g2', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ngf*4, no_bias=no_bias)\n",
    "    gbn2 = BatchNorm(g2, name='gbn2', fix_gamma=fix_gamma, eps=eps)\n",
    "    gact2 = mx.sym.Activation(gbn2, name='gact2', act_type='relu')\n",
    "\n",
    "    g3 = mx.sym.Deconvolution(gact2, name='g3', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ngf*2, no_bias=no_bias)\n",
    "    gbn3 = BatchNorm(g3, name='gbn3', fix_gamma=fix_gamma, eps=eps)\n",
    "    gact3 = mx.sym.Activation(gbn3, name='gact3', act_type='relu')\n",
    "\n",
    "    g4 = mx.sym.Deconvolution(gact3, name='g4', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ngf, no_bias=no_bias)\n",
    "    gbn4 = BatchNorm(g4, name='gbn4', fix_gamma=fix_gamma, eps=eps)\n",
    "    gact4 = mx.sym.Activation(gbn4, name='gact4', act_type='relu')\n",
    "\n",
    "    g5 = mx.sym.Deconvolution(gact4, name='g5', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=nc, no_bias=no_bias)\n",
    "    gout = mx.sym.Activation(g5, name='gact5', act_type='tanh')\n",
    "\n",
    "    data = mx.sym.Variable('data')\n",
    "    label = mx.sym.Variable('label')\n",
    "\n",
    "    d1 = mx.sym.Convolution(data, name='d1', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ndf, no_bias=no_bias)\n",
    "    dact1 = mx.sym.LeakyReLU(d1, name='dact1', act_type='leaky', slope=0.2)\n",
    "\n",
    "    d2 = mx.sym.Convolution(dact1, name='d2', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ndf*2, no_bias=no_bias)\n",
    "    dbn2 = BatchNorm(d2, name='dbn2', fix_gamma=fix_gamma, eps=eps)\n",
    "    dact2 = mx.sym.LeakyReLU(dbn2, name='dact2', act_type='leaky', slope=0.2)\n",
    "\n",
    "    d3 = mx.sym.Convolution(dact2, name='d3', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ndf*4, no_bias=no_bias)\n",
    "    dbn3 = BatchNorm(d3, name='dbn3', fix_gamma=fix_gamma, eps=eps)\n",
    "    dact3 = mx.sym.LeakyReLU(dbn3, name='dact3', act_type='leaky', slope=0.2)\n",
    "\n",
    "    d4 = mx.sym.Convolution(dact3, name='d4', kernel=(4,4), stride=(2,2), pad=(1,1), num_filter=ndf*8, no_bias=no_bias)\n",
    "    dbn4 = BatchNorm(d4, name='dbn4', fix_gamma=fix_gamma, eps=eps)\n",
    "    dact4 = mx.sym.LeakyReLU(dbn4, name='dact4', act_type='leaky', slope=0.2)\n",
    "\n",
    "    d5 = mx.sym.Convolution(dact4, name='d5', kernel=(4,4), num_filter=1, no_bias=no_bias)\n",
    "    d5 = mx.sym.Flatten(d5)\n",
    "\n",
    "    dloss = mx.sym.LogisticRegressionOutput(data=d5, label=label, name='dloss')\n",
    "    return gout, dloss\n",
    "\n",
    "def get_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    np.random.seed(1234) # set seed for deterministic ordering\n",
    "    p = np.random.permutation(mnist.data.shape[0])\n",
    "    X = mnist.data[p]\n",
    "    X = X.reshape((70000, 28, 28))\n",
    "\n",
    "    X = np.asarray([cv2.resize(x, (64,64)) for x in X])\n",
    "\n",
    "    X = X.astype(np.float32)/(255.0/2) - 1.0\n",
    "    X = X.reshape((70000, 1, 64, 64))\n",
    "    X = np.tile(X, (1, 3, 1, 1))\n",
    "    X_train = X[:60000]\n",
    "    X_test = X[60000:]\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "class RandIter(mx.io.DataIter):\n",
    "    def __init__(self, batch_size, ndim):\n",
    "        self.batch_size = batch_size\n",
    "        self.ndim = ndim\n",
    "        self.provide_data = [('rand', (batch_size, ndim, 1, 1))]\n",
    "        self.provide_label = []\n",
    "\n",
    "    def iter_next(self):\n",
    "        return True\n",
    "\n",
    "    def getdata(self):\n",
    "        return [mx.random.normal(0, 1.0, shape=(self.batch_size, self.ndim, 1, 1))]\n",
    "\n",
    "class ImagenetIter(mx.io.DataIter):\n",
    "    def __init__(self, path, batch_size, data_shape):\n",
    "        self.internal = mx.io.ImageRecordIter(\n",
    "            path_imgrec = path,\n",
    "            data_shape  = data_shape,\n",
    "            batch_size  = batch_size,\n",
    "            rand_crop   = True,\n",
    "            rand_mirror = True,\n",
    "            max_crop_size = 256,\n",
    "            min_crop_size = 192)\n",
    "        self.provide_data = [('data', (batch_size,) + data_shape)]\n",
    "        self.provide_label = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.internal.reset()\n",
    "\n",
    "    def iter_next(self):\n",
    "        return self.internal.iter_next()\n",
    "\n",
    "    def getdata(self):\n",
    "        data = self.internal.getdata()\n",
    "        data = data * (2.0/255.0)\n",
    "        data -= 1\n",
    "        return [data]\n",
    "\n",
    "def fill_buf(buf, i, img, shape):\n",
    "    n = buf.shape[0]/shape[1]\n",
    "    m = buf.shape[1]/shape[0]\n",
    "\n",
    "    sx = (i%m)*shape[0]\n",
    "    sy = (i/m)*shape[1]\n",
    "    buf[sy:sy+shape[1], sx:sx+shape[0], :] = img\n",
    "\n",
    "def visual(title, X):\n",
    "    assert len(X.shape) == 4\n",
    "    X = X.transpose((0, 2, 3, 1))\n",
    "    X = np.clip((X+1.0)*(255.0/2.0), 0, 255).astype(np.uint8)\n",
    "    n = np.ceil(np.sqrt(X.shape[0]))\n",
    "    buff = np.zeros((n*X.shape[1], n*X.shape[2], X.shape[3]), dtype=np.uint8)\n",
    "    for i, img in enumerate(X):\n",
    "        fill_buf(buff, i, img, X.shape[1:3])\n",
    "    buff = cv2.cvtColor(buff, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(title, buff)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    # =============setting============\n",
    "    dataset = 'mnist'\n",
    "    imgnet_path = './train.rec'\n",
    "    ndf = 64\n",
    "    ngf = 64\n",
    "    nc = 3\n",
    "    batch_size = 64\n",
    "    Z = 100\n",
    "    lr = 0.0002\n",
    "    beta1 = 0.5\n",
    "    ctx = mx.gpu(0)\n",
    "    check_point = False\n",
    "\n",
    "    symG, symD = make_dcgan_sym(ngf, ndf, nc)\n",
    "    #mx.viz.plot_network(symG, shape={'rand': (batch_size, 100, 1, 1)}).view()\n",
    "    #mx.viz.plot_network(symD, shape={'data': (batch_size, nc, 64, 64)}).view()\n",
    "\n",
    "    # ==============data==============\n",
    "    if dataset == 'mnist':\n",
    "        X_train, X_test = get_mnist()\n",
    "        train_iter = mx.io.NDArrayIter(X_train, batch_size=batch_size)\n",
    "    elif dataset == 'imagenet':\n",
    "        train_iter = ImagenetIter(imgnet_path, batch_size, (3, 64, 64))\n",
    "    rand_iter = RandIter(batch_size, Z)\n",
    "    label = mx.nd.zeros((batch_size,), ctx=ctx)\n",
    "\n",
    "    # =============module G=============\n",
    "    modG = mx.mod.Module(symbol=symG, data_names=('rand',), label_names=None, context=ctx)\n",
    "    modG.bind(data_shapes=rand_iter.provide_data)\n",
    "    modG.init_params(initializer=mx.init.Normal(0.02))\n",
    "    modG.init_optimizer(\n",
    "        optimizer='adam',\n",
    "        optimizer_params={\n",
    "            'learning_rate': lr,\n",
    "            'wd': 0.,\n",
    "            'beta1': beta1,\n",
    "        })\n",
    "    mods = [modG]\n",
    "\n",
    "    # =============module D=============\n",
    "    modD = mx.mod.Module(symbol=symD, data_names=('data',), label_names=('label',), context=ctx)\n",
    "    modD.bind(data_shapes=train_iter.provide_data,\n",
    "              label_shapes=[('label', (batch_size,))],\n",
    "              inputs_need_grad=True)\n",
    "    modD.init_params(initializer=mx.init.Normal(0.02))\n",
    "    modD.init_optimizer(\n",
    "        optimizer='adam',\n",
    "        optimizer_params={\n",
    "            'learning_rate': lr,\n",
    "            'wd': 0.,\n",
    "            'beta1': beta1,\n",
    "        })\n",
    "    mods.append(modD)\n",
    "\n",
    "\n",
    "    # ============printing==============\n",
    "    def norm_stat(d):\n",
    "        return mx.nd.norm(d)/np.sqrt(d.size)\n",
    "    mon = mx.mon.Monitor(10, norm_stat, pattern=\".*output|d1_backward_data\", sort=True)\n",
    "    mon = None\n",
    "    if mon is not None:\n",
    "        for mod in mods:\n",
    "            pass\n",
    "\n",
    "    def facc(label, pred):\n",
    "        pred = pred.ravel()\n",
    "        label = label.ravel()\n",
    "        return ((pred > 0.5) == label).mean()\n",
    "\n",
    "    def fentropy(label, pred):\n",
    "        pred = pred.ravel()\n",
    "        label = label.ravel()\n",
    "        return -(label*np.log(pred+1e-12) + (1.-label)*np.log(1.-pred+1e-12)).mean()\n",
    "\n",
    "    mG = mx.metric.CustomMetric(fentropy)\n",
    "    mD = mx.metric.CustomMetric(fentropy)\n",
    "    mACC = mx.metric.CustomMetric(facc)\n",
    "\n",
    "    print 'Training...'\n",
    "    stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "\n",
    "    # =============train===============\n",
    "    for epoch in range(100):\n",
    "        train_iter.reset()\n",
    "        for t, batch in enumerate(train_iter):\n",
    "            rbatch = rand_iter.next()\n",
    "\n",
    "            if mon is not None:\n",
    "                mon.tic()\n",
    "\n",
    "            modG.forward(rbatch, is_train=True)\n",
    "            outG = modG.get_outputs()\n",
    "\n",
    "            # update discriminator on fake\n",
    "            label[:] = 0\n",
    "            modD.forward(mx.io.DataBatch(outG, [label]), is_train=True)\n",
    "            modD.backward()\n",
    "            #modD.update()\n",
    "            gradD = [[grad.copyto(grad.context) for grad in grads] for grads in modD._exec_group.grad_arrays]\n",
    "\n",
    "            modD.update_metric(mD, [label])\n",
    "            modD.update_metric(mACC, [label])\n",
    "\n",
    "            # update discriminator on real\n",
    "            label[:] = 1\n",
    "            batch.label = [label]\n",
    "            modD.forward(batch, is_train=True)\n",
    "            modD.backward()\n",
    "            for gradsr, gradsf in zip(modD._exec_group.grad_arrays, gradD):\n",
    "                for gradr, gradf in zip(gradsr, gradsf):\n",
    "                    gradr += gradf\n",
    "            modD.update()\n",
    "\n",
    "            modD.update_metric(mD, [label])\n",
    "            modD.update_metric(mACC, [label])\n",
    "\n",
    "            # update generator\n",
    "            label[:] = 1\n",
    "            modD.forward(mx.io.DataBatch(outG, [label]), is_train=True)\n",
    "            modD.backward()\n",
    "            diffD = modD.get_input_grads()\n",
    "            modG.backward(diffD)\n",
    "            modG.update()\n",
    "\n",
    "            mG.update([label], modD.get_outputs())\n",
    "\n",
    "\n",
    "            if mon is not None:\n",
    "                mon.toc_print()\n",
    "\n",
    "            t += 1\n",
    "            if t % 10 == 0:\n",
    "                print 'epoch:', epoch, 'iter:', t, 'metric:', mACC.get(), mG.get(), mD.get()\n",
    "                mACC.reset()\n",
    "                mG.reset()\n",
    "                mD.reset()\n",
    "\n",
    "                visual('gout', outG[0].asnumpy())\n",
    "                diff = diffD[0].asnumpy()\n",
    "                diff = (diff - diff.mean())/diff.std()\n",
    "                visual('diff', diff)\n",
    "                visual('data', batch.data[0].asnumpy())\n",
    "\n",
    "        if check_point:\n",
    "            print 'Saving...'\n",
    "            modG.save_params('%s_G_%s-%04d.params'%(dataset, stamp, epoch))\n",
    "            modD.save_params('%s_D_%s-%04d.params'%(dataset, stamp, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for shixiangwan: "
     ]
    }
   ],
   "source": [
    "!sudo pip install sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
