{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> loading ...  finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-17 17:24:05.439345. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# 载入one-hot数据\n",
    "\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "# def load_one_hot_data():\n",
    "data_list = []\n",
    "print '>> loading ... ',\n",
    "for line in open('/home01/shixiangwan/deep_learning/protein_location/RNA-all-long-CD-HIT.fasta'):\n",
    "    if line[0] != '>':\n",
    "        line = line.strip().replace('A', '1').replace('U', '2').replace('C', '3').replace('G', '4')\n",
    "        data_list.append(map(int, list(line)))\n",
    "depth = len(max(data_list, key=len))\n",
    "print 'finished.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_list length: 7091\n",
      "0.210196\n",
      "0.561533\n",
      "1\n",
      "data_list length: 1484\n",
      "0.0377910000002\n",
      "0.132156\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-17 18:57:32.208196. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "data_mx = []\n",
    "count = 0\n",
    "start = time.clock()\n",
    "for elem in range(len(data_list)):\n",
    "    print 'data_list length:', len(data_list[elem])\n",
    "    tmp_mx = mx.nd.one_hot(mx.nd.array(data_list[elem], dtype=np.int32), depth=depth)\\\n",
    "        .asnumpy().reshape(len(data_list[elem]) * depth)\n",
    "    tmp_mx = np.append(tmp_mx, np.zeros(len(data_list[elem]) * depth))\n",
    "    data_mx.append(list(tmp_mx))\n",
    "    count += 1\n",
    "    print count\n",
    "    if count == 2:\n",
    "        break\n",
    "\n",
    "print time.clock() - start, 'ms'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-17 19:00:03.626092. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# %prun load_one_hot_data()\n",
    "\n",
    "# data_mx = load_one_hot_data()\n",
    "one_hot = open('/home01/shixiangwan/deep_learning/protein_location/one_hot.csv', 'w')\n",
    "for i in range(len(data_mx)):\n",
    "    one_hot.write(','.join(map(str, data_mx[i]))+'\\n')\n",
    "one_hot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1218\n",
      "2436\n",
      "2436\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "def load_data():\n",
    "    train_set = []\n",
    "    label_set = []\n",
    "    for line in open(\"RNA-all-SC-PseDNC-General.csv\"):\n",
    "        a_line = ''\n",
    "        for i in range(34):\n",
    "            a_line += line + ','\n",
    "        train_set.append(map(float, a_line.strip(',').split(',')))\n",
    "    for line in open(\"labels_1.txt\"):\n",
    "#         label_set.append(map(float, line.strip().split(',')))\n",
    "        label_set.append(float(line.strip()))\n",
    "    # 提取二分类平衡数据集\n",
    "    lbl_0 = label_set.count(0.0)\n",
    "    lbl_1 = label_set.count(1.0)\n",
    "    lbl_less = 1\n",
    "    lbl_less_num = lbl_1\n",
    "    if max(lbl_0, lbl_1) == lbl_1:\n",
    "        lbl_less = 0\n",
    "        lbl_less_num = lbl_0\n",
    "    train_set2 = []\n",
    "    label_set2 = []\n",
    "    count_more = 0\n",
    "    for i in range(len(label_set)):\n",
    "        if label_set[i] == lbl_less:\n",
    "            train_set2.append(train_set[i])\n",
    "            label_set2.append(label_set[i])\n",
    "        else:\n",
    "            if count_more < lbl_less_num:\n",
    "                train_set2.append(train_set[i])\n",
    "                label_set2.append(label_set[i])\n",
    "                count_more += 1\n",
    "    print lbl_less, lbl_less_num\n",
    "    return train_set2, label_set2\n",
    "\n",
    "# train_set2, label_set2 = load_data()\n",
    "# print len(train_set2)\n",
    "# print len(label_set2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shixiangwan/.local/lib/python2.7/site-packages/ipykernel/__main__.py:132: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "INFO:root:Start training with [gpu(1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1218\n",
      "(1948, 1156)\n",
      "(244, 1156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 63934.15 samples/sec\tTrain-accuracy=0.530000\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 71173.07 samples/sec\tTrain-accuracy=0.535000\n",
      "INFO:root:Epoch[0] Batch [600]\tSpeed: 71126.55 samples/sec\tTrain-accuracy=0.530000\n",
      "INFO:root:Epoch[0] Batch [800]\tSpeed: 71774.62 samples/sec\tTrain-accuracy=0.545000\n",
      "INFO:root:Epoch[0] Batch [1000]\tSpeed: 70561.88 samples/sec\tTrain-accuracy=0.555000\n",
      "INFO:root:Epoch[0] Batch [1200]\tSpeed: 68987.65 samples/sec\tTrain-accuracy=0.495000\n",
      "INFO:root:Epoch[0] Batch [1400]\tSpeed: 70990.45 samples/sec\tTrain-accuracy=0.540000\n",
      "INFO:root:Epoch[0] Batch [1600]\tSpeed: 71118.95 samples/sec\tTrain-accuracy=0.525000\n",
      "INFO:root:Epoch[0] Batch [1800]\tSpeed: 69715.32 samples/sec\tTrain-accuracy=0.485000\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=2.805\n",
      "INFO:root:Epoch[0] Validation-accuracy=1.000000\n",
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-17 12:02:00.958612. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# %load protein.py\n",
    "\n",
    "import logging\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# 数据标准化处理\n",
    "def norm_stat(d):\n",
    "    return mx.nd.norm(d) / np.sqrt(d.size)\n",
    "\n",
    "\n",
    "# 多层感知机\n",
    "def set_mlp():\n",
    "    data = mx.symbol.Variable('data')\n",
    "    data = mx.sym.Flatten(data=data)\n",
    "    fc1 = mx.symbol.FullyConnected(data=data, name='fc1', num_hidden=128)\n",
    "    act1 = mx.symbol.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "    fc2 = mx.symbol.FullyConnected(data=act1, name='fc2', num_hidden=64)\n",
    "    act2 = mx.symbol.Activation(data=fc2, name='relu2', act_type=\"relu\")\n",
    "    fc3 = mx.symbol.FullyConnected(data=act2, name='fc3', num_hidden=3)\n",
    "    mlp = mx.symbol.SoftmaxOutput(data=fc3, name='softmax')\n",
    "    return mlp\n",
    "\n",
    "\n",
    "# Basic Conv + BN + ReLU factory\n",
    "def ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(0, 0), act_type=\"relu\"):\n",
    "    # there is an optional parameter ```wrokshpace``` may influece convolution performance\n",
    "    # default, the workspace is set to 256(MB)\n",
    "    # you may set larger value, but convolution layer only requires its needed but not exactly\n",
    "    # MXNet will handle reuse of workspace without parallelism conflict\n",
    "    conv = mx.symbol.Convolution(data=data, workspace=256,\n",
    "                                 num_filter=num_filter, kernel=kernel, stride=stride, pad=pad)\n",
    "    bn = mx.symbol.BatchNorm(data=conv)\n",
    "    act = mx.symbol.Activation(data = bn, act_type=act_type)\n",
    "    return act\n",
    "\n",
    "\n",
    "# A Simple Downsampling Factory\n",
    "def DownsampleFactory(data, ch_3x3):\n",
    "    # conv 3x3\n",
    "    conv = ConvFactory(data=data, kernel=(3, 3), stride=(2, 2), num_filter=ch_3x3, pad=(1, 1))\n",
    "    # pool\n",
    "    pool = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(2, 2), pad=(1,1), pool_type='max')\n",
    "    # concat\n",
    "    concat = mx.symbol.Concat(*[conv, pool])\n",
    "    return concat\n",
    "\n",
    "\n",
    "# A Simple module\n",
    "def SimpleFactory(data, ch_1x1, ch_3x3):\n",
    "    # 1x1\n",
    "    conv1x1 = ConvFactory(data=data, kernel=(1, 1), pad=(0, 0), num_filter=ch_1x1)\n",
    "    # 3x3\n",
    "    conv3x3 = ConvFactory(data=data, kernel=(3, 3), pad=(1, 1), num_filter=ch_3x3)\n",
    "    #concat\n",
    "    concat = mx.symbol.Concat(*[conv1x1, conv3x3])\n",
    "    return concat\n",
    "\n",
    "\n",
    "def set_cifar10():\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "    conv1 = ConvFactory(data=data, kernel=(3,3), pad=(1,1), num_filter=96, act_type=\"relu\")\n",
    "    in3a = SimpleFactory(conv1, 32, 32)\n",
    "    in3b = SimpleFactory(in3a, 32, 48)\n",
    "    in3c = DownsampleFactory(in3b, 80)\n",
    "    in4a = SimpleFactory(in3c, 112, 48)\n",
    "    in4b = SimpleFactory(in4a, 96, 64)\n",
    "    in4c = SimpleFactory(in4b, 80, 80)\n",
    "    in4d = SimpleFactory(in4c, 48, 96)\n",
    "    in4e = DownsampleFactory(in4d, 96)\n",
    "    in5a = SimpleFactory(in4e, 176, 160)\n",
    "    in5b = SimpleFactory(in5a, 176, 160)\n",
    "    pool = mx.symbol.Pooling(data=in5b, pool_type=\"avg\", kernel=(7,7), name=\"global_avg\")\n",
    "    flatten = mx.symbol.Flatten(data=pool)\n",
    "    fc = mx.symbol.FullyConnected(data=flatten, num_hidden=10)\n",
    "    softmax = mx.symbol.SoftmaxOutput(name='softmax',data=fc)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "# 卷积神经网络\n",
    "def set_con():\n",
    "    data = mx.symbol.Variable('data')\n",
    "    # first conv layer\n",
    "    mx.sym.Activation\n",
    "    conv1 = mx.sym.Convolution(data=data, kernel=(5, 5), num_filter=20)\n",
    "    tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # second conv layer\n",
    "    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\n",
    "    tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2, 2), stride=(2, 2))\n",
    "    # first fullc layer\n",
    "    flatten = mx.sym.Flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=2)\n",
    "    # softmax loss\n",
    "    lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "    return lenet\n",
    "\n",
    "\n",
    "def to4d(data):\n",
    "    print data.shape\n",
    "    return data.reshape(data.shape[0], 1, 34, 34)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # data\n",
    "    train_set, label_set = load_data()\n",
    "    all_number = len(label_set)\n",
    "    split_tv = int(0.8*all_number)\n",
    "    split_tt = int(0.9*all_number)\n",
    "    train_iter = mx.io.NDArrayIter(mx.nd.array(to4d(np.array(train_set[0:split_tv]))),\n",
    "                                  mx.nd.array(np.array(label_set[0:split_tv])),\n",
    "                                  shuffle=True)\n",
    "    validate_iter = mx.io.NDArrayIter(mx.nd.array(to4d(np.array(train_set[split_tv:split_tt]))),\n",
    "                                   mx.nd.array(np.array(label_set[split_tv:split_tt])),\n",
    "                                   shuffle=True)\n",
    "\n",
    "    # train\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    model = mx.model.FeedForward(ctx=mx.gpu(1), # [mx.gpu(i) for i in range(4)]\n",
    "                                 symbol=set_con(), # set_mlp(), set_con(), set_cifar10()\n",
    "                                 num_epoch=1,\n",
    "                                 learning_rate=0.1,\n",
    "                                 momentum=0.9,\n",
    "                                 wd=0.00001)\n",
    "\n",
    "    batch_size = 100\n",
    "    result = model.fit(X = train_iter,\n",
    "                       eval_data = validate_iter,\n",
    "                       batch_end_callback = mx.callback.Speedometer(batch_size, 200)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "[  1.00000000e+00   1.54688876e-36]\n",
      "(244, 1156)\n",
      "----------------------------------------------------------------------\n",
      "precision\t\tmse\n",
      "1.0 \t\t0.5 \t\t0.0\n",
      "\n",
      "right/all/rate: 244 244 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-17 12:11:02.198520. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# 分析结果\n",
    "\n",
    "test_set = train_set[split_tt:]\n",
    "test_lbl = label_set[split_tt:]\n",
    "\n",
    "count = 0\n",
    "r_num = 0\n",
    "results = open('results.csv', 'w')\n",
    "for i in range(len(test_set)):\n",
    "    test_val = np.array(test_set[i]).reshape(1, 1, 34, 34)\n",
    "    prob = model.predict(test_val)\n",
    "    print prob[0]\n",
    "    predict =  ','.join(str(j) for j in prob[0])\n",
    "    # origin = ','.join(str(j) for j in test_lbl[i])\n",
    "    origin = str(test_lbl[i])\n",
    "    for j in range(len(prob[0])):\n",
    "        p_val = 0\n",
    "        if prob[0][j] >= 0.5:\n",
    "            p_val = 1\n",
    "        # if p_val == test_lbl[i][j]:\n",
    "        if p_val == test_lbl[i]:\n",
    "            r_num += 1\n",
    "    results.write(predict + '\\n' + origin + '\\n\\n')\n",
    "    count += 1\n",
    "#     print predict\n",
    "#     print origin\n",
    "#     print\n",
    "#     if count == 20:\n",
    "#         break\n",
    "results.close()\n",
    "\n",
    "# performance matrics\n",
    "test_iter = mx.io.NDArrayIter(mx.nd.array(to4d(np.array(test_set))),\n",
    "                              mx.nd.array(np.array(test_lbl)),\n",
    "                              shuffle=True)\n",
    "f1, mse, acc = model.score(test_iter, ['f1', 'mse', 'acc'])\n",
    "print '----------------------------------------------------------------------'\n",
    "print 'precision\\t\\t' + 'mse'\n",
    "print acc, '\\t\\t', mse, '\\t\\t', f1\n",
    "\n",
    "# print '\\nright/all/rate:', r_num, count*len(label_set[0]), float(r_num)/(count*len(label_set[0]))\n",
    "print '\\nright/all/rate:', r_num, count, float(r_num)/(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "推测：\n",
    "\n",
    "在更复杂的蛋白质二级结构预测方面，卷积神经网络应该有着更好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-17 15:57:12.689383. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# mx.nd.one_hot(mx.nd.array(np.array([1, 0, 2, 0]), dtype=np.int32), depth=5).asnumpy()\n",
    "mx.nd.one_hot(mx.nd.array([1, 2, 3, 4, 1], dtype=np.int32), depth=10).asnumpy()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
